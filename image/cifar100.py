# from fastapi import FastAPI, UploadFile, File, HTTPException
# import io
# import torch
# from torchvision import transforms
# import torch.nn as nn
# from PIL import Image
# import streamlit as st
#
#
#
# transform = transforms.Compose([
#     transforms.Resize((32, 32)),  # –¥–æ–±–∞–≤—å —ç—Ç–æ
#     transforms.ToTensor(),
#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
# ])
#
# class CheckImageVGG16(nn.Module):
#   def __init__(self):
#     super().__init__()
#     self.first = nn.Sequential(
#         nn.Conv2d(3, 16, kernel_size=3, padding=1), nn.ReLU(), #32
#         nn.Conv2d(16, 32, kernel_size=3, padding=1),nn.ReLU(),
#         nn.MaxPool2d(2),
#
#         nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(),
#         nn.Conv2d(64, 128, kernel_size=3, padding=1),nn.ReLU(), #16
#         nn.MaxPool2d(2),
#
#         nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(),
#         nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.ReLU(),
#         nn.MaxPool2d(2),
#
#     )
#     self.second = nn.Sequential(
#         nn.Flatten(),
#         nn.Linear(512*4*4, 1024),
#         nn.ReLU(),
#         nn.Dropout(0.5),
#         nn.Linear(1024, 100)
#     )
#
#   def forward(self, x):
#     x = self.first(x)
#     x = self.second(x)
#     return x
#
# check_image_app = FastAPI()
# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# model = CheckImageVGG16()
# state = torch.load('model_cifar100.pth', map_location=device)
# model.load_state_dict(state)
# model = model.to(device)
# model.eval()
#
# class_name = [
#     'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle',
#     'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle',
#     'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup',
#     'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house',
#     'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man',
#     'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid',
#     'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy',
#     'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal',
#     'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar',
#     'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor',
#     'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm'
# ]
#
#
# def cifar100_image():
#     st.title('CIFAR100 AI model')
#     st.text('Upload image with a number, and model will recognize it')
#
#     file = st.file_uploader('Choose of drop an image', type=['svg', 'png', 'jpg', 'jpeg'])
#
#     if not file:
#         st.warning('No file is uploaded')
#     else:
#         st.image(file, caption='Uploaded image')
#         if st.button('Recognize the image'):
#             try:
#                 image_data = file.read()
#                 if not image_data:
#                     raise HTTPException(status_code=400, detail='No image is given')
#                 img = Image.open(io.BytesIO(image_data))
#                 img_tensor = transform(img).unsqueeze(0).to(device)
#
#                 with torch.no_grad():
#                     y_pred = model(img_tensor)
#                     pred = y_pred.argmax(dim=1).item()
#
#                 st.success({"Answer": class_name[pred]})
#
#             except Exception as e:
#                 raise HTTPException(status_code=500, detail=str(e))
#

import io
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import streamlit as st
from fastapi import HTTPException

# ===========================
# üé® –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
# ===========================
st.set_page_config(
    page_title="CIFAR100 AI –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä",
    page_icon="üñºÔ∏è",
    layout="centered"
)

# ===========================
# ‚öôÔ∏è –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
# ===========================
transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# ===========================
# ‚öôÔ∏è –ö–ª–∞—Å—Å –º–æ–¥–µ–ª–∏
# ===========================
class CheckImageVGG16(nn.Module):
    def __init__(self):
        super().__init__()
        self.first = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=1), nn.ReLU(),
            nn.Conv2d(16, 32, kernel_size=3, padding=1), nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(),
            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(),
            nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.ReLU(),
            nn.MaxPool2d(2),
        )
        self.second = nn.Sequential(
            nn.Flatten(),
            nn.Linear(512*4*4, 1024),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(1024, 100)
        )

    def forward(self, x):
        x = self.first(x)
        x = self.second(x)
        return x

# ===========================
# ‚öôÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
# ===========================
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = CheckImageVGG16().to(device)
state = torch.load('model_cifar100.pth', map_location=device)
model.load_state_dict(state)
model.eval()

# ===========================
# ‚öôÔ∏è –ö–ª–∞—Å—Å—ã CIFAR100
# ===========================
class_name = [
    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle',
    'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle',
    'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup',
    'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house',
    'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man',
    'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid',
    'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy',
    'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal',
    'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar',
    'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor',
    'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm'
]

# ===========================
# üß† –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Streamlit
# ===========================
def cifar100_image():
    st.markdown("<h1 style='text-align:center; color:#00ADB5;'>üñºÔ∏è CIFAR100 AI –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align:center; color:gray;'>–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∏ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∂–µ—Ç –µ–≥–æ –∫–ª–∞—Å—Å.</p>", unsafe_allow_html=True)
    st.divider()

    file = st.file_uploader('–í—ã–±–µ—Ä–∏—Ç–µ –∏–ª–∏ –ø–µ—Ä–µ—Ç–∞—â–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', type=['png', 'jpg', 'jpeg'])
    if not file:
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã.")
        st.stop()

    st.image(file, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_column_width=True)

    if st.button("üîç –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å"):
        try:
            image_data = file.read()
            img = Image.open(io.BytesIO(image_data))
            img_tensor = transform(img).unsqueeze(0).to(device)

            with torch.no_grad():
                y_pred = model(img_tensor)
                pred = y_pred.argmax(dim=1).item()
                prediction = class_name[pred]

            st.success(f"‚úÖ **–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ:** {prediction}")

        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

# ===========================
# üöÄ –ó–∞–ø—É—Å–∫
# ===========================
if __name__ == "__main__":
    cifar100_image()

# from fastapi import FastAPI, UploadFile, File, HTTPException
# import io
# import torch
# from torchvision import transforms
# import torch.nn as nn
# from PIL import Image
# import streamlit as st
#
#
#
# train_transform = transforms.Compose([
#     transforms.Resize((32, 32)),
#     transforms.RandomHorizontalFlip(),
#     transforms.RandomRotation(10),
#     transforms.ToTensor(),
#     transforms.Normalize((0.5,), (0.5,))
# ])
#
#
# class CheckImage2(nn.Module):
#     def __init__(self, num_classes=10):
#         super().__init__()
#         self.first2 = nn.Sequential(
#             nn.Conv2d(3, 32, kernel_size=3, padding=1),
#             nn.BatchNorm2d(32),
#             nn.ReLU(),
#             nn.MaxPool2d(2),
#
#             nn.Conv2d(32, 64, kernel_size=3, padding=1),
#             nn.ReLU(),
#             nn.MaxPool2d(2),
#
#             nn.Conv2d(64, 128, kernel_size=3, padding=1),
#             nn.ReLU(),
#             nn.MaxPool2d(2),
#
#             nn.Conv2d(128, 256, kernel_size=3, padding=1),
#             nn.ReLU(),
#             nn.MaxPool2d(2),
#         )
#
#         # —É–∑–Ω–∞—ë–º –≤—ã—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
#         with torch.no_grad():
#             dummy = torch.zeros(1, 3, 32, 32)  # –ø–æ–º–µ–Ω—è–π 32x32 –Ω–∞ —Å–≤–æ–π —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞
#             out = self.first2(dummy)
#             out_features = out.view(1, -1).size(1)
#
#         self.second2 = nn.Sequential(
#             nn.Flatten(),
#             nn.Linear(out_features, 256),
#             nn.ReLU(),
#             nn.Linear(256, num_classes)
#         )
#
#     def forward(self, x):
#         x = self.first2(x)
#         x = self.second2(x)
#         return x
#
#
#
# check_image_app = FastAPI()
# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# model = CheckImage2()
# model.load_state_dict(torch.load('model.pth', map_location=device))
# model.to(device)
# model.eval()
#
#
# class_names = [
#      'airplane',
#      'automobile',
#      'bird',
#      'cat',
#      'deer',
#      'dog',
#      'frog',
#      'horse',
#      'ship',
#      'truck'
# ]
# def cifar10_image():
#     st.title('CIFAR10 AI model')
#     st.text('Upload image with a number, and model will recognize it')
#
#     file = st.file_uploader('Choose of drop an image', type=['svg', 'png', 'jpg', 'jpeg'])
#
#     if not file:
#         st.warning('No file is uploaded')
#     else:
#         st.image(file, caption='Uploaded image')
#         if st.button('Recognize the image'):
#             try:
#                 image_data = file.read()
#                 if not image_data:
#                     raise HTTPException(status_code=400, detail='No image is given')
#
#                 img = Image.open(io.BytesIO(image_data)).convert("RGB")  # ‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ RGB
#                 img_tensor = train_transform(img).unsqueeze(0).to(device)
#
#                 with torch.no_grad():
#                     y_pred = model(img_tensor)
#                     pred = y_pred.argmax(dim=1).item()
#
#                 st.success({"Answer": class_names[pred]})
#
#             except Exception as e:
#                 raise HTTPException(status_code=500, detail=str(e))
#
#

import io
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import streamlit as st
from fastapi import HTTPException

# ===========================
# üé® –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
# ===========================
st.set_page_config(
    page_title="CIFAR10 AI –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä",
    page_icon="üñºÔ∏è",
    layout="centered"
)

# ===========================
# ‚öôÔ∏è –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
# ===========================
train_transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# ===========================
# ‚öôÔ∏è –ö–ª–∞—Å—Å –º–æ–¥–µ–ª–∏
# ===========================
class CheckImage2(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.first2 = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
        )

        # –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–∞
        with torch.no_grad():
            dummy = torch.zeros(1, 3, 32, 32)
            out = self.first2(dummy)
            out_features = out.view(1, -1).size(1)

        self.second2 = nn.Sequential(
            nn.Flatten(),
            nn.Linear(out_features, 256),
            nn.ReLU(),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        x = self.first2(x)
        x = self.second2(x)
        return x

# ===========================
# ‚öôÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
# ===========================
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = CheckImage2().to(device)
model.load_state_dict(torch.load('model.pth', map_location=device))
model.eval()

# ===========================
# ‚öôÔ∏è –ö–ª–∞—Å—Å—ã CIFAR10
# ===========================
class_names = [
     'airplane', 'automobile', 'bird', 'cat', 'deer',
     'dog', 'frog', 'horse', 'ship', 'truck'
]

# ===========================
# üß† –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Streamlit
# ===========================
def cifar10_image():
    st.markdown("<h1 style='text-align:center; color:#00ADB5;'>üñºÔ∏è CIFAR10 AI –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align:center; color:gray;'>–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∏ –º–æ–¥–µ–ª—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç –µ–≥–æ –∫–ª–∞—Å—Å.</p>", unsafe_allow_html=True)
    st.divider()

    file = st.file_uploader('–í—ã–±–µ—Ä–∏—Ç–µ –∏–ª–∏ –ø–µ—Ä–µ—Ç–∞—â–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', type=['png', 'jpg', 'jpeg'])
    if not file:
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã.")
        st.stop()

    st.image(file, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_column_width=True)

    if st.button("üîç –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å"):
        try:
            image_data = file.read()
            img = Image.open(io.BytesIO(image_data)).convert("RGB")
            img_tensor = train_transform(img).unsqueeze(0).to(device)

            with torch.no_grad():
                y_pred = model(img_tensor)
                pred = y_pred.argmax(dim=1).item()
                prediction = class_names[pred]

            st.success(f"‚úÖ **–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ:** {prediction}")

        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

# ===========================
# üöÄ –ó–∞–ø—É—Å–∫
# ===========================
if __name__ == "__main__":
    cifar10_image()

